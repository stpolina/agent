{
    "title": "Weakly-Supervised Image Semantic Segmentation Based on Superpixel Region Merging",
    "authors": "Quanchun Jiang , Olamide Timothy Tawose , Songwen Pei , Xiaodong Chen , Linhua Jiang , Jiayao Wang and Dongfang Zhao",
    "affiliations": "1\nShanghai Key Lab of Modern Optical Systems, School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai 200093, China\n2\nDepartment of Computer Science and Engineering, University of Nevada, Reno, NV 89557, USA\n3\nInformation Science and Technology Research, Shanghai Advanced Research Institute, Chinese Academy of Sciences, No. 99 Haike Rd., Zhangjiang, Pudong, Shanghai 201210, China\n4\nDepartment of Computer Science, University of California, Davis, CA 95661, USA\n*\nAuthors to whom correspondence should be addressed.",
    "year": "2019",
    "url": "https://www.mdpi.com/2504-2289/3/2/31",
    "article type": "Article",
    "abstract": "In this paper, we propose a semantic segmentation method based on superpixel region merging and convolutional neural network (CNN), referred to as regional merging neural network (RMNN). Image annotation has always been an important role in weakly-supervised semantic segmentation. Most methods use manual labeling. In this paper, super-pixels with similar features are combined using the relationship between each pixel after super-pixel segmentation to form a plurality of super-pixel blocks. Rough predictions are generated by the fully convolutional networks (FCN) so that certain super-pixel blocks will be labeled. We perceive and find other positive areas in an iterative way through the marked areas. This reduces the feature extraction vector and reduces the data dimension due to super-pixels. The algorithm not only uses superpixel merging to narrow down the target’s range but also compensates for the lack of weakly-supervised semantic segmentation at the pixel level. In the training of the network, we use the method of region merging to improve the accuracy of contour recognition. Our extensive experiments demonstrated the effectiveness of the proposed method with the PASCAL VOC 2012 dataset. In particular, evaluation results show that the mean intersection over union (mIoU) score of our method reaches as high as 44.6%. Because the cavity convolution is in the pooled downsampling operation, it does not degrade the network’s receptive field, thereby ensuring the accuracy of image semantic segmentation. The findings of this work thus open the door to leveraging the dilated convolution to improve the recognition accuracy of small objects. View Full-Text",
    "keywords": "Keywords: superpixel; CNN; region merging; SLIC; weakly-supervised",
    "publication history": "Received: 24 April 2019 / Revised: 1 June 2019 / Accepted: 3 June 2019 / Published: 10 June 2019"
}